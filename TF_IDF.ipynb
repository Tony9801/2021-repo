{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhavuD/z6aWqI/gdU7TUSx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tony9801/2021-repo/blob/main/TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the first try on our model. Using 552 samples.\n"
      ],
      "metadata": {
        "id": "hwBXOSXKxbzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Import requried modules"
      ],
      "metadata": {
        "id": "-buViI-43xeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from email.parser import BytesParser\n",
        "from email.policy import default\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "ZIIQTVbm3GeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Import data\n",
        "\n",
        "Only use \"Subject\", \"Content-Type\" and \"To\" attributes for the header part.\n",
        "Two folders: training -> training data\n",
        "test -> testing data"
      ],
      "metadata": {
        "id": "KxUkID_H35Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_data(directory):\n",
        "    emails = []\n",
        "    labels = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith('.eml'):\n",
        "                with open(os.path.join(root, file), 'rb') as f:\n",
        "                    msg = BytesParser(policy=default).parse(f)\n",
        "                    \n",
        "                    subject = msg.get('Subject', '')\n",
        "                    content_type = msg.get('Content-Type', '')\n",
        "                    from_ = msg.get('To')\n",
        "\n",
        "                    email_content = msg.get_payload(decode=True)\n",
        "                    if isinstance(email_content, bytes):\n",
        "                        email_content = email_content.decode(errors='ignore')\n",
        "                    \n",
        "                    \n",
        "                    combined_content = f\"{subject} {content_type}{from_}{email_content}\"\n",
        "                    emails.append(combined_content)\n",
        "                    labels.append(1 if 'phishing' in root else 0)\n",
        "    return emails, labels\n",
        "\n",
        "\n",
        "emails, labels = load_and_preprocess_data('/content/train')\n",
        "print('total number of training samples is ' + str(len(emails)))\n",
        "\n",
        "\n",
        "test_emails, test_labels = load_and_preprocess_data('/content/test')\n",
        "print('total number of testing samples is ' + str(len(test_emails)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3TJDV0n3HRQ",
        "outputId": "98bee34e-619f-45a3-8861-e41ac4ffa018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of training samples is 2826\n",
            "total number of testing samples is 719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Feature Extraction\n",
        "\n",
        "    TF-IDF, which stands for Term Frequency-Inverse Document Frequency, is a numerical statistic used in information retrieval, natural language processing, and text mining to quantify the importance of a term in a document within a collection or corpus of documents. The TF-IDF value increases proportionally to the number of times a term appears in a document and is offset by the frequency of the term in the corpus."
      ],
      "metadata": {
        "id": "IwS7Gafg-VBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=8000)\n",
        "email_features = vectorizer.fit_transform(emails).toarray()\n",
        "test_email_features = vectorizer.fit_transform(test_emails).toarray()"
      ],
      "metadata": {
        "id": "OJZjKAO7-X8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = vectorizer.fit_transform(emails).toarray()\n",
        "X_test = vectorizer.transform(test_emails).toarray()\n",
        "y_train = np.array(labels)\n",
        "y_test = np.array(test_labels)"
      ],
      "metadata": {
        "id": "0o7ske8t_yKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Define the model 1"
      ],
      "metadata": {
        "id": "cb62ARZP_0DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(8000,)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.4)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.2)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YoDDdDcQ_5cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Train the model 1"
      ],
      "metadata": {
        "id": "DKLhE22n_8i-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsCTz4EHAFMb",
        "outputId": "60adb6d0-ee5a-4e24-f2b3-95b01edf9c4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "36/36 [==============================] - 3s 32ms/step - loss: 33.0258 - accuracy: 0.6735 - val_loss: 23.7932 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 17.7942 - accuracy: 0.6920 - val_loss: 12.8003 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "36/36 [==============================] - 1s 22ms/step - loss: 9.3928 - accuracy: 0.6969 - val_loss: 6.8994 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "36/36 [==============================] - 1s 21ms/step - loss: 4.9509 - accuracy: 0.7252 - val_loss: 3.8051 - val_accuracy: 0.2173\n",
            "Epoch 5/20\n",
            "36/36 [==============================] - 1s 23ms/step - loss: 2.6714 - accuracy: 0.7920 - val_loss: 2.1953 - val_accuracy: 0.6908\n",
            "Epoch 6/20\n",
            "36/36 [==============================] - 1s 21ms/step - loss: 1.5173 - accuracy: 0.8947 - val_loss: 1.3476 - val_accuracy: 0.8781\n",
            "Epoch 7/20\n",
            "36/36 [==============================] - 1s 24ms/step - loss: 0.9364 - accuracy: 0.9456 - val_loss: 0.9240 - val_accuracy: 0.9223\n",
            "Epoch 8/20\n",
            "36/36 [==============================] - 1s 34ms/step - loss: 0.6449 - accuracy: 0.9611 - val_loss: 0.6765 - val_accuracy: 0.9558\n",
            "Epoch 9/20\n",
            "36/36 [==============================] - 1s 34ms/step - loss: 0.4991 - accuracy: 0.9673 - val_loss: 0.5491 - val_accuracy: 0.9647\n",
            "Epoch 10/20\n",
            "36/36 [==============================] - 1s 30ms/step - loss: 0.4139 - accuracy: 0.9752 - val_loss: 0.4636 - val_accuracy: 0.9788\n",
            "Epoch 11/20\n",
            "36/36 [==============================] - 1s 22ms/step - loss: 0.3642 - accuracy: 0.9810 - val_loss: 0.4237 - val_accuracy: 0.9753\n",
            "Epoch 12/20\n",
            "36/36 [==============================] - 1s 21ms/step - loss: 0.3217 - accuracy: 0.9832 - val_loss: 0.3745 - val_accuracy: 0.9859\n",
            "Epoch 13/20\n",
            "36/36 [==============================] - 1s 21ms/step - loss: 0.3005 - accuracy: 0.9854 - val_loss: 0.3850 - val_accuracy: 0.9664\n",
            "Epoch 14/20\n",
            "36/36 [==============================] - 1s 21ms/step - loss: 0.2790 - accuracy: 0.9823 - val_loss: 0.3108 - val_accuracy: 0.9912\n",
            "Epoch 15/20\n",
            "36/36 [==============================] - 1s 22ms/step - loss: 0.2705 - accuracy: 0.9850 - val_loss: 0.3184 - val_accuracy: 0.9841\n",
            "Epoch 16/20\n",
            "36/36 [==============================] - 1s 22ms/step - loss: 0.2518 - accuracy: 0.9867 - val_loss: 0.2878 - val_accuracy: 0.9876\n",
            "Epoch 17/20\n",
            "36/36 [==============================] - 1s 21ms/step - loss: 0.2420 - accuracy: 0.9858 - val_loss: 0.2977 - val_accuracy: 0.9806\n",
            "Epoch 18/20\n",
            "36/36 [==============================] - 1s 22ms/step - loss: 0.2314 - accuracy: 0.9858 - val_loss: 0.2546 - val_accuracy: 0.9929\n",
            "Epoch 19/20\n",
            "36/36 [==============================] - 1s 21ms/step - loss: 0.2234 - accuracy: 0.9885 - val_loss: 0.2824 - val_accuracy: 0.9788\n",
            "Epoch 20/20\n",
            "36/36 [==============================] - 1s 22ms/step - loss: 0.2147 - accuracy: 0.9903 - val_loss: 0.2552 - val_accuracy: 0.9876\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc07f3ee280>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Evaluate the model"
      ],
      "metadata": {
        "id": "HcSQWebVBnFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "accuracy_1 = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy_1:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "FPR = FP / (FP + TN)\n",
        "FNR = FN / (FN + TP)\n",
        "\n",
        "print(f\"False Positive Rate: {FPR:.4f}\")\n",
        "print(f\"False Negative Rate: {FNR:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUU4jhE5Bwzc",
        "outputId": "d2c5980e-7176-4d4a-ed7d-d750385f1fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 6ms/step\n",
            "Accuracy: 0.9930\n",
            "False Positive Rate: 0.0075\n",
            "False Negative Rate: 0.0063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Use recurrent layers"
      ],
      "metadata": {
        "id": "k8b25udzKmFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 100\n",
        "vocab_size = 10000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(emails)\n",
        "train_sequences = tokenizer.texts_to_sequences(emails)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_emails)\n",
        "\n",
        "X_train_RNN = pad_sequences(train_sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "X_test_RNN = pad_sequences(test_sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
        "\n",
        "embedding_size = 200\n",
        "\n",
        "model_RNN = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_size, input_length=max_sequence_length),\n",
        "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
        "    tf.keras.layers.GlobalMaxPooling1D(),\n",
        "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.1)),\n",
        "    tf.keras.layers.Dropout(0.8),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model_RNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_RNN.fit(X_train_RNN, y_train, epochs=13, batch_size=32, validation_split=0.2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFD30yDgKuoB",
        "outputId": "be8e3dff-a6de-4305-bd3a-cea29b5b6fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "71/71 [==============================] - 12s 112ms/step - loss: 3.3646 - accuracy: 0.6889 - val_loss: 2.4116 - val_accuracy: 0.7792\n",
            "Epoch 2/13\n",
            "71/71 [==============================] - 8s 112ms/step - loss: 1.3892 - accuracy: 0.9323 - val_loss: 1.1100 - val_accuracy: 0.9558\n",
            "Epoch 3/13\n",
            "71/71 [==============================] - 7s 100ms/step - loss: 0.5811 - accuracy: 0.9889 - val_loss: 0.4119 - val_accuracy: 0.9859\n",
            "Epoch 4/13\n",
            "71/71 [==============================] - 8s 107ms/step - loss: 0.2806 - accuracy: 0.9898 - val_loss: 0.5006 - val_accuracy: 0.8799\n",
            "Epoch 5/13\n",
            "71/71 [==============================] - 8s 117ms/step - loss: 0.1755 - accuracy: 0.9934 - val_loss: 0.1617 - val_accuracy: 0.9859\n",
            "Epoch 6/13\n",
            "71/71 [==============================] - 7s 96ms/step - loss: 0.1267 - accuracy: 0.9960 - val_loss: 0.1469 - val_accuracy: 0.9823\n",
            "Epoch 7/13\n",
            "71/71 [==============================] - 8s 110ms/step - loss: 0.1108 - accuracy: 0.9956 - val_loss: 0.1348 - val_accuracy: 0.9841\n",
            "Epoch 8/13\n",
            "71/71 [==============================] - 7s 96ms/step - loss: 0.0925 - accuracy: 0.9978 - val_loss: 0.1189 - val_accuracy: 0.9859\n",
            "Epoch 9/13\n",
            "71/71 [==============================] - 8s 114ms/step - loss: 0.0852 - accuracy: 0.9987 - val_loss: 0.1287 - val_accuracy: 0.9841\n",
            "Epoch 10/13\n",
            "71/71 [==============================] - 7s 103ms/step - loss: 0.0791 - accuracy: 0.9978 - val_loss: 0.1351 - val_accuracy: 0.9806\n",
            "Epoch 11/13\n",
            "71/71 [==============================] - 7s 104ms/step - loss: 0.0752 - accuracy: 0.9987 - val_loss: 0.1105 - val_accuracy: 0.9859\n",
            "Epoch 12/13\n",
            "71/71 [==============================] - 8s 111ms/step - loss: 0.0676 - accuracy: 0.9969 - val_loss: 0.0907 - val_accuracy: 0.9912\n",
            "Epoch 13/13\n",
            "71/71 [==============================] - 7s 96ms/step - loss: 0.0696 - accuracy: 0.9982 - val_loss: 0.0989 - val_accuracy: 0.9876\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc07f0766a0>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_RNN = (model_RNN.predict(X_test_RNN) > 0.5).astype(int)\n",
        "accuracy2 = accuracy_score(y_test, y_pred_RNN)\n",
        "print(f\"Accuracy: {accuracy2:.4f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_RNN)\n",
        "\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "FPR = FP / (FP + TN)\n",
        "FNR = FN / (FN + TP)\n",
        "\n",
        "print(f\"False Positive Rate: {FPR:.4f}\")\n",
        "print(f\"False Negative Rate: {FNR:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwnuoiuMcd5x",
        "outputId": "2a25a904-6be7-4af2-8443-35ee31d7f6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 1s 28ms/step\n",
            "Accuracy: 0.9930\n",
            "False Positive Rate: 0.0050\n",
            "False Negative Rate: 0.0094\n"
          ]
        }
      ]
    }
  ]
}